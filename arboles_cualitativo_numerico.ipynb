{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#import utileria as ut\n",
        "#import arboles_numericos as an\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "from collections import Counter\n",
        "#import numpy as np\n",
        "#import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "Pf1qz9UorlY0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lee_csv(archivo, atributos=None, separador=','):\n",
        "    \"\"\"\n",
        "    Lee un archivo CSV y regresa una lista de diccionarios.\n",
        "    Se asume que la primera linea contiene el nombre de los atributos.\n",
        "\n",
        "    Parámetros\n",
        "    ----------\n",
        "    archivo : str\n",
        "        Nombre del archivo CSV.\n",
        "    atributos : list(str)\n",
        "        Lista de atributos a considerar. Si es None, se asume que la primera linea contiene los nombres de los atributos.\n",
        "    separador : str\n",
        "        Separador de columnas.\n",
        "    \"\"\"\n",
        "    with open(archivo, 'r') as f:\n",
        "        lineas = f.readlines()\n",
        "    if atributos is None:\n",
        "        columnas = lineas[0].strip().split(separador)\n",
        "    else:\n",
        "        columnas = atributos\n",
        "    datos = []\n",
        "    for l in lineas[1:]:\n",
        "        datos.append({c: v for c, v in zip(columnas, l.strip().split(','))})\n",
        "    return datos"
      ],
      "metadata": {
        "id": "N5M3gBXdsr0r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Arboles cualitativos"
      ],
      "metadata": {
        "id": "DZejJroNsgOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entrena_arbol(datos, target, clase_default,\n",
        "                  max_profundidad=None, acc_nodo=1, min_ejemplos=0):\n",
        "    \"\"\"\n",
        "    Entrena un árbol de desición utilizando el criterio de entropía\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    datos: list(dict)\n",
        "        Una lista de diccionarios donde cada diccionario representa una instancia.\n",
        "        Cada diccionario tiene al menos un par llave-valor, donde la llave es el nombre de un atributo y el valor es el valor del atributo.\n",
        "        Todos los diccionarios tienen la misma llave-valor.\n",
        "    target: str\n",
        "        El nombre del atributo que se quiere predecir\n",
        "    clase_default: str\n",
        "        El valor de la clase por default\n",
        "    max_profundidad: int\n",
        "        La máxima profundidad del árbol. Si es None, no hay límite de profundidad\n",
        "    acc_nodo: int\n",
        "        El porcentaje de acierto mínimo para considerar un nodo como hoja\n",
        "    min_ejemplos: int\n",
        "        El número mínimo de ejemplos para considerar un nodo como hoja\n",
        "\n",
        "    Regresa:\n",
        "    --------\n",
        "    nodo: Nodo\n",
        "        El nodo raíz del árbol de desición\n",
        "\n",
        "    \"\"\"\n",
        "    atributos = list(datos[0].keys())\n",
        "    atributos.remove(target)\n",
        "\n",
        "    # Criterios para deterinar si es un nodo hoja\n",
        "    if  len(datos) == 0 or len(atributos) == 0:\n",
        "        return NodoQ(terminal=True, clase_default=clase_default)\n",
        "\n",
        "    clases = Counter(d[target] for d in datos)\n",
        "    clase_default = clases.most_common(1)[0][0]\n",
        "\n",
        "    if (max_profundidad == 0 or\n",
        "        len(datos) <= min_ejemplos or\n",
        "        clases.most_common(1)[0][1] / len(datos) >= acc_nodo):\n",
        "\n",
        "        return NodoQ(terminal=True, clase_default=clase_default)\n",
        "\n",
        "    variable = selecciona_variable(datos, target, atributos)\n",
        "    nodo = NodoQ(terminal=False, atributo=variable, clase_default=clase_default)\n",
        "\n",
        "    for valor in set(d[variable] for d in datos):\n",
        "        datos_hijo = [d for d in datos if d[variable] == valor]\n",
        "        nodo.hijos[valor] = entrena_arbol(\n",
        "            datos_hijo,\n",
        "            target,\n",
        "            clase_default,\n",
        "            max_profundidad - 1 if max_profundidad is not None else None,\n",
        "            acc_nodo, min_ejemplos\n",
        "        )\n",
        "    return nodo"
      ],
      "metadata": {
        "id": "VyBlbx6cvwHl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selecciona_variable(datos, target, atributos):\n",
        "    \"\"\"\n",
        "    Selecciona el atributo que mejor separa las clases\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    datos: list(dict)\n",
        "        Una lista de diccionarios donde cada diccionario representa una instancia.\n",
        "        Cada diccionario tiene al menos un par llave-valor, donde la llave es el nombre de un atributo y el valor es el valor del atributo. Todos los diccionarios tienen la misma llave-valor.\n",
        "    target: str\n",
        "        El nombre del atributo que se quiere predecir\n",
        "    atributos: list(str)\n",
        "        La lista de atributos a considerar\n",
        "\n",
        "    Regresa:\n",
        "    --------\n",
        "    atributo: str\n",
        "        El nombre del atributo que mejor separa las clases\n",
        "    \"\"\"\n",
        "\n",
        "    entropia = entropia_clase(datos, target)\n",
        "    ganancia = {a: ganancia_informacion(datos, target, a, entropia) for a in atributos}\n",
        "    return max(ganancia, key=ganancia.get)"
      ],
      "metadata": {
        "id": "nY5oOWKmv137"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entropia_clase(datos, target):\n",
        "    \"\"\"\n",
        "    Calcula la entropía de la clase\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    datos: list(dict)\n",
        "        Una lista de diccionarios donde cada diccionario representa una instancia.\n",
        "        Cada diccionario tiene al menos un par llave-valor, donde la llave es el nombre de un atributo y el valor es el valor del atributo. Todos los diccionarios tienen la misma llave-valor.\n",
        "    target: str\n",
        "        El nombre del atributo que se quiere predecir\n",
        "\n",
        "    Regresa:\n",
        "    --------\n",
        "    entropia: float\n",
        "        La entropía de la clase\n",
        "    \"\"\"\n",
        "\n",
        "    clases = Counter(d[target] for d in datos)\n",
        "    total = sum(clases.values())\n",
        "    return -sum((c/total) * math.log2(c/total) for c in clases.values())"
      ],
      "metadata": {
        "id": "6WkIFT57v4_x"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ganancia_informacion(datos, target, atributo, entropia):\n",
        "    \"\"\"\n",
        "    Calcula la ganancia de información de un atributo\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    datos: list(dict)\n",
        "        Una lista de diccionarios donde cada diccionario representa una instancia.\n",
        "        Cada diccionario tiene al menos un par llave-valor, donde la llave es el nombre de un atributo y el valor es el valor del atributo. Todos los diccionarios tienen la misma llave-valor.\n",
        "    target: str\n",
        "        El nombre del atributo que se quiere predecir\n",
        "    atributo: str\n",
        "        El nombre del atributo a considerar\n",
        "    entropia: float\n",
        "        La entropía de la clase\n",
        "\n",
        "    Regresa:\n",
        "    --------\n",
        "    ganancia: float\n",
        "        La ganancia de información del atributo\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(datos)\n",
        "    ganancia = entropia\n",
        "\n",
        "    for valor in set(d[atributo] for d in datos):\n",
        "        datos_valor = [d for d in datos if d[atributo] == valor]\n",
        "        ganancia -= (len(datos_valor) / total) * entropia_clase(datos_valor, target)\n",
        "    return ganancia"
      ],
      "metadata": {
        "id": "sFYYwtbiwAm1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predice_arbol(arbol, datos):\n",
        "    return [arbol.predice(d) for d in datos]"
      ],
      "metadata": {
        "id": "sfV1Vex2wExT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalua_arbol(arbol, datos, target):\n",
        "    predicciones = predice_arbol(arbol, datos)\n",
        "    return sum(1 for p, d in zip(predicciones, datos) if p == d[target]) / len(datos)"
      ],
      "metadata": {
        "id": "jE3u3xrgwG-s"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imprime_arbol(nodo, nivel=0, valor=\" \"):\n",
        "    if nodo.terminal:\n",
        "        print(\"    \" * nivel + f\"Si valor es {valor}, la clase es {nodo.clase_default}\")\n",
        "    else:\n",
        "        if valor == \" \":\n",
        "            print(\"    \" * nivel\n",
        "                  + f\"Si el atributo es {nodo.atributo} entonces:\")\n",
        "        else:\n",
        "            print(\"    \" * nivel\n",
        "                  + f\"Si el valor es {valor} y el atributo es {nodo.atributo} entonces:\")\n",
        "        for valor, hijo in nodo.hijos.items():\n",
        "            imprime_arbol(hijo, nivel + 1, valor)"
      ],
      "metadata": {
        "id": "G-qPlaZWwL_k"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NodoQ:\n",
        "    def __init__(self, terminal, clase_default, atributo=None):\n",
        "        self.terminal = terminal\n",
        "        self.clase_default = clase_default\n",
        "        self.atributo = atributo\n",
        "        self.hijos = {}\n",
        "\n",
        "    def predice(self, instancia):\n",
        "        if self.terminal:\n",
        "            return self.clase_default\n",
        "        valor = instancia[self.atributo]\n",
        "        if valor not in self.hijos:\n",
        "            return self.clase_default\n",
        "        return self.hijos[valor].predice(instancia)"
      ],
      "metadata": {
        "id": "hVPNTJt0wP_N"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    datos = [\n",
        "        {\"color\": \"rojo\", \"tamano\": \"grande\", \"sabor\": \"dulce\", \"clase\": \"manzana\"},\n",
        "        {\"color\": \"verde\", \"tamano\": \"grande\", \"sabor\": \"dulce\", \"clase\": \"sandia\"},\n",
        "        {\"color\": \"rojo\", \"tamano\": \"pequeno\", \"sabor\": \"dulce\", \"clase\": \"uva\"},\n",
        "        {\"color\": \"verde\", \"tamano\": \"grande\", \"sabor\": \"amargo\", \"clase\": \"sandia\"},\n",
        "        {\"color\": \"verde\", \"tamano\": \"pequeno\", \"sabor\": \"amargo\", \"clase\": \"uva\"},\n",
        "        {\"color\": \"rojo\", \"tamano\": \"grande\", \"sabor\": \"amargo\", \"clase\": \"manzana\"},\n",
        "        {\"color\": \"rojo\", \"tamano\": \"pequeno\", \"sabor\": \"dulce\", \"clase\": \"uva\"},\n",
        "        {\"color\": \"verde\", \"tamano\": \"pequeno\", \"sabor\": \"dulce\", \"clase\": \"uva\"},\n",
        "        {\"color\": \"rojo\", \"tamano\": \"grande\", \"sabor\": \"amargo\", \"clase\": \"manzana\"},\n",
        "        {\"color\": \"verde\", \"tamano\": \"pequeno\", \"sabor\": \"amargo\", \"clase\": \"uva\"},\n",
        "        {\"color\": \"rojo\", \"tamano\": \"pequeno\", \"sabor\": \"amargo\", \"clase\": \"manzana\"},\n",
        "        {\"color\": \"verde\", \"tamano\": \"grande\", \"sabor\": \"dulce\", \"clase\": \"sandia\"},\n",
        "        {\"color\": \"rojo\", \"tamano\": \"pequeno\", \"sabor\": \"dulce\", \"clase\": \"uva\"},\n",
        "        {\"color\": \"verde\", \"tamano\": \"pequeno\", \"sabor\": \"amargo\", \"clase\": \"uva\"},\n",
        "        {\"color\": \"rojo\", \"tamano\": \"grande\", \"sabor\": \"amargo\", \"clase\": \"manzana\"},\n",
        "        {\"color\": \"verde\", \"tamano\": \"pequeno\", \"sabor\": \"dulce\", \"clase\": \"uva\"},\n",
        "        {\"color\": \"rojo\", \"tamano\": \"grande\", \"sabor\": \"amargo\", \"clase\": \"manzana\"}\n",
        "    ]\n",
        "\n",
        "    raiz = entrena_arbol(datos, \"clase\", \"uva\")\n",
        "    imprime_arbol(raiz)\n",
        "\n",
        "    acc = evalua_arbol(raiz, datos, \"clase\")\n",
        "    print(f\"El acierto en los mismos datos que se entrenó es {acc}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "XDEXPSltwTo1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMlFhZziwWn9",
        "outputId": "cfa03414-65e3-4db9-ef7f-d4116af2ed84"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Si el atributo es tamano entonces:\n",
            "    Si el valor es pequeno y el atributo es color entonces:\n",
            "        Si el valor es rojo y el atributo es sabor entonces:\n",
            "            Si valor es amargo, la clase es manzana\n",
            "            Si valor es dulce, la clase es uva\n",
            "        Si valor es verde, la clase es uva\n",
            "    Si el valor es grande y el atributo es color entonces:\n",
            "        Si valor es rojo, la clase es manzana\n",
            "        Si valor es verde, la clase es sandia\n",
            "El acierto en los mismos datos que se entrenó es 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#arboles numericos"
      ],
      "metadata": {
        "id": "Bznyxkf5stMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entrena_arbol(datos, target, clase_default,\n",
        "                  max_profundidad=None, acc_nodo=1.0, min_ejemplos=0,\n",
        "                  variables_seleccionadas=None):\n",
        "    \"\"\"\n",
        "    Entrena un árbol de desición utilizando el criterio de entropía\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    datos: list(dict)\n",
        "        Una lista de diccionarios donde cada diccionario representa una instancia.\n",
        "        Cada diccionario tiene al menos un par llave-valor, donde la llave es el nombre de un atributo y el valor es el valor del atributo.\n",
        "        Todos los diccionarios tienen la misma llave-valor.\n",
        "    target: str\n",
        "        El nombre del atributo que se quiere predecir\n",
        "    clase_default: str\n",
        "        El valor de la clase por default\n",
        "    max_profundidad: int\n",
        "        La máxima profundidad del árbol. Si es None, no hay límite de profundidad\n",
        "    acc_nodo: int\n",
        "        El porcentaje de acierto mínimo para considerar un nodo como hoja\n",
        "    min_ejemplos: int\n",
        "        El número mínimo de ejemplos para considerar un nodo como hoja\n",
        "    variables_seleccionadas: list(str)\n",
        "        Lista de variables a considerar. Si es None, se consideran todas las variables, esto apica para árboles aleagtorios y lo tendrán que implementar en la tarea.\n",
        "\n",
        "    Regresa:\n",
        "    --------\n",
        "    nodo: Nodo\n",
        "        El nodo raíz del árbol de desición\n",
        "\n",
        "    \"\"\"\n",
        "    atributos = list(datos[0].keys())\n",
        "    atributos.remove(target)\n",
        "\n",
        "    # Criterios para deterinar si es un nodo hoja\n",
        "    if  len(datos) == 0 or len(atributos) == 0:\n",
        "        return NodoN(terminal=True, clase_default=clase_default)\n",
        "\n",
        "    clases = Counter(d[target] for d in datos)\n",
        "    clase_default = clases.most_common(1)[0][0]\n",
        "\n",
        "    if (max_profundidad == 0 or\n",
        "        len(datos) <= min_ejemplos or\n",
        "        clases.most_common(1)[0][1] / len(datos) >= acc_nodo):\n",
        "\n",
        "        return NodoN(terminal=True, clase_default=clase_default)\n",
        "\n",
        "    variable, valor = selecciona_variable_valor(\n",
        "        datos, target, atributos\n",
        "    )\n",
        "    nodo = NodoN(\n",
        "        terminal=False,\n",
        "        clase_default=clase_default,\n",
        "        atributo=variable,\n",
        "        valor=valor\n",
        "    )\n",
        "    nodo.hijo_menor = entrena_arbol(\n",
        "        [d for d in datos if d[variable] < valor],\n",
        "        target,\n",
        "        clase_default,\n",
        "        max_profundidad - 1 if max_profundidad is not None else None,\n",
        "        acc_nodo, min_ejemplos, variables_seleccionadas\n",
        "    )\n",
        "    nodo.hijo_mayor = entrena_arbol(\n",
        "        [d for d in datos if d[variable] >= valor],\n",
        "        target,\n",
        "        clase_default,\n",
        "        max_profundidad - 1 if max_profundidad is not None else None,\n",
        "        acc_nodo, min_ejemplos, variables_seleccionadas\n",
        "    )\n",
        "    return nodo"
      ],
      "metadata": {
        "id": "j5OPOkgcsfkN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selecciona_variable_valor(datos, target, atributos):\n",
        "    \"\"\"\n",
        "    Selecciona el atributo y el valor que mejor separa las clases\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    datos: list(dict)\n",
        "        Una lista de diccionarios donde cada diccionario representa una instancia.\n",
        "        Cada diccionario tiene al menos un par llave-valor, donde la llave es el nombre de un atributo y el valor es el valor del atributo. Todos los diccionarios tienen la misma llave-valor.\n",
        "    target: str\n",
        "        El nombre del atributo que se quiere predecir\n",
        "    atributos: list(str)\n",
        "        La lista de atributos a considerar\n",
        "\n",
        "    Regresa:\n",
        "    --------\n",
        "    atributo: str\n",
        "        El nombre del atributo que mejor separa las clases\n",
        "    valor: float\n",
        "        El valor del atributo que mejor separa las clases\n",
        "    \"\"\"\n",
        "\n",
        "    entropia = entropia_clase(datos, target)\n",
        "    mejor = max(\n",
        "        ((a, maxima_ganancia_informacion(datos, target, a, entropia))\n",
        "            for a in atributos),\n",
        "        key=lambda x: x[1][1]\n",
        "    )\n",
        "    return mejor[0], mejor[1][0]"
      ],
      "metadata": {
        "id": "ppyni9XxtDzq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entropia_clase(datos, target):\n",
        "    \"\"\"\n",
        "    Calcula la entropía de la clase\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    datos: list(dict)\n",
        "        Una lista de diccionarios donde cada diccionario representa una instancia.\n",
        "        Cada diccionario tiene al menos un par llave-valor, donde la llave es el nombre de un atributo y el valor es el valor del atributo. Todos los diccionarios tienen la misma llave-valor.\n",
        "    target: str\n",
        "        El nombre del atributo que se quiere predecir\n",
        "\n",
        "    Regresa:\n",
        "    --------\n",
        "    entropia: float\n",
        "        La entropía de la clase\n",
        "    \"\"\"\n",
        "\n",
        "    clases = Counter(d[target] for d in datos)\n",
        "    total = sum(clases.values())\n",
        "    return -sum((c/total) * math.log2(c/total) for c in clases.values())\n"
      ],
      "metadata": {
        "id": "YqgWZWhLtG-S"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maxima_ganancia_informacion(datos, target, atributo, entropia):\n",
        "    \"\"\"\n",
        "    Calcula la ganancia de información de un atributo\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    datos: list(dict)\n",
        "        Una lista de diccionarios donde cada diccionario representa una instancia.\n",
        "        Cada diccionario tiene al menos un par llave-valor, donde la llave es el nombre de un atributo y el valor es el valor del atributo. Todos los diccionarios tienen la misma llave-valor.\n",
        "    target: str\n",
        "        El nombre del atributo que se quiere predecir\n",
        "    atributo: str\n",
        "        El nombre del atributo a considerar\n",
        "    entropia: float\n",
        "        La entropía de la clase\n",
        "\n",
        "    Regresa:\n",
        "    --------\n",
        "    valor: float\n",
        "        El valor del atributo que mejor separa las clases\n",
        "    ganancia: float\n",
        "        La ganancia de información del atributo dividiendo en ese valor\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    lista_valores = [(d[atributo], d[target]) for d in datos]\n",
        "    lista_valores.sort(key=lambda x: x[0])\n",
        "    lista_valor_ganancia = []\n",
        "    for (v1, v2) in zip(lista_valores[:-1], lista_valores[1:]):\n",
        "        if v1[1] != v2[1]:\n",
        "            valor = (v1[0] + v2[0]) / 2\n",
        "            ganancia = ganancia_informacion(datos, target, atributo, valor, entropia)\n",
        "            lista_valor_ganancia.append((valor, ganancia))\n",
        "    return max(lista_valor_ganancia, key=lambda x: x[1])"
      ],
      "metadata": {
        "id": "iyuHqbQ_tKYl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ganancia_informacion(datos, target, atributo, valor, entropia):\n",
        "    \"\"\"\n",
        "    Calcula la ganancia de información de un atributo dividiendo en un valor\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    datos: list(dict)\n",
        "        Una lista de diccionarios donde cada diccionario representa una instancia.\n",
        "        Cada diccionario tiene al menos un par llave-valor, donde la llave es el nombre de un atributo y el valor es el valor del atributo. Todos los diccionarios tienen la misma llave-valor.\n",
        "    target: str\n",
        "        El nombre del atributo que se quiere predecir\n",
        "    atributo: str\n",
        "        El nombre del atributo a considerar\n",
        "    valor: float\n",
        "        El valor del atributo a considerar\n",
        "    entropia: float\n",
        "        La entropía de la clase\n",
        "\n",
        "    Regresa:\n",
        "    --------\n",
        "    ganancia: float\n",
        "        La ganancia de información del atributo dividiendo en ese valor\n",
        "    \"\"\"\n",
        "\n",
        "    datos_menor = [d for d in datos if d[atributo] < valor]\n",
        "    datos_mayor = [d for d in datos if d[atributo] >= valor]\n",
        "\n",
        "    entropia_menor = entropia_clase(datos_menor, target)\n",
        "    entropia_mayor = entropia_clase(datos_mayor, target)\n",
        "\n",
        "    total = len(datos)\n",
        "    total_menor = len(datos_menor)\n",
        "    total_mayor = len(datos_mayor)\n",
        "\n",
        "    return (\n",
        "        entropia\n",
        "        - (total_menor / total) * entropia_menor\n",
        "        - (total_mayor / total) * entropia_mayor\n",
        "    )"
      ],
      "metadata": {
        "id": "j5TGY0tQtPoZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predice_arbol(arbol, datos):\n",
        "    return [arbol.predice(d) for d in datos]"
      ],
      "metadata": {
        "id": "5-hGBSdetSii"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalua_arbol(arbol, datos, target):\n",
        "    predicciones = predice_arbol(arbol, datos)\n",
        "    return sum(1 for p, d in zip(predicciones, datos) if p == d[target]) / len(datos)"
      ],
      "metadata": {
        "id": "gNWKJ8-XtUD_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imprime_arbol(nodo, nivel=0):\n",
        "    if nodo.terminal:\n",
        "        print(\"    \" * nivel + f\"La clase es {nodo.clase_default}\")\n",
        "    else:\n",
        "        print(\"    \" * nivel + f\"Si {nodo.atributo} < {nodo.valor} entonces:\")\n",
        "        imprime_arbol(nodo.hijo_menor, nivel + 1)\n",
        "        print(\"    \" * nivel + f\"Si {nodo.atributo} >= {nodo.valor} entonces:\")\n",
        "        imprime_arbol(nodo.hijo_mayor, nivel + 1)"
      ],
      "metadata": {
        "id": "vtwyEvb9tYLP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NodoN:\n",
        "    def __init__(self, terminal, clase_default, atributo=None, valor=None):\n",
        "        self.terminal = terminal\n",
        "        self.clase_default = clase_default\n",
        "        self.atributo = atributo\n",
        "        self.valor = valor\n",
        "        self.hijo_menor = None\n",
        "        self.hijo_mayor = None\n",
        "\n",
        "    def predice(self, instancia):\n",
        "        if self.terminal:\n",
        "            return self.clase_default\n",
        "        if instancia[self.atributo] < self.valor:\n",
        "            return self.hijo_menor.predice(instancia)\n",
        "        return self.hijo_mayor.predice(instancia)"
      ],
      "metadata": {
        "id": "tMzexXentagW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    datos = [\n",
        "        {\"atributo1\": 1, \"atributo2\": 1, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 2, \"atributo2\": 1, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 3, \"atributo2\": 1, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 4, \"atributo2\": 1, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 1, \"atributo2\": 2, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 2, \"atributo2\": 2, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 3, \"atributo2\": 2, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 4, \"atributo2\": 2, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 1, \"atributo2\": 3, \"clase\": \"negativa\"},\n",
        "        {\"atributo1\": 2, \"atributo2\": 3, \"clase\": \"negativa\"},\n",
        "        {\"atributo1\": 3, \"atributo2\": 3, \"clase\": \"negativa\"},\n",
        "        {\"atributo1\": 4, \"atributo2\": 3, \"clase\": \"negativa\"},\n",
        "        {\"atributo1\": 1, \"atributo2\": 4, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 2, \"atributo2\": 4, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 3, \"atributo2\": 4, \"clase\": \"positiva\"},\n",
        "        {\"atributo1\": 4, \"atributo2\": 4, \"clase\": \"positiva\"},\n",
        "\n",
        "   ]\n",
        "\n",
        "    raiz = entrena_arbol(datos, \"clase\", \"positiva\")\n",
        "    imprime_arbol(raiz)\n",
        "\n",
        "    acc = evalua_arbol(raiz, datos, \"clase\")\n",
        "    print(f\"El acierto en los mismos datos que se entrenó es {acc}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "1CaGnyHGthqK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcDWCCattj2Y",
        "outputId": "63b5878a-1755-415d-a980-2a69e2aabc5a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Si atributo2 < 2.5 entonces:\n",
            "    La clase es positiva\n",
            "Si atributo2 >= 2.5 entonces:\n",
            "    Si atributo2 < 3.5 entonces:\n",
            "        La clase es negativa\n",
            "    Si atributo2 >= 3.5 entonces:\n",
            "        La clase es positiva\n",
            "El acierto en los mismos datos que se entrenó es 1.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Te damos la bienvenida a Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}